# src/utils/scv.py
"""
SCV: Semantic Consistency Verification (2026 Enhanced Version)
è¯­ä¹‰ä¸€è‡´æ€§éªŒè¯æ¨¡å—

============================================================================
å­¦æœ¯åˆ›æ–°ç‚¹ (2026å¹´å¢å¼º):
============================================================================
1. å‡è´Ÿæ ·æœ¬è¿‡æ»¤: åŸºäº NLI æ¨¡å‹è¯†åˆ«å¹¶ä¸¢å¼ƒ"å®é™…æ­£ç¡®ä½†è¢«æ ‡è®°ä¸ºè´Ÿ"çš„æ ·æœ¬
2. ã€2026 æ–°å¢ã€‘CoT-JSON ä¸€è‡´æ€§æ£€æµ‹: éªŒè¯æ¨ç†è¿‡ç¨‹ä¸æœ€ç»ˆè¾“å‡ºçš„ä¸€è‡´æ€§
3. ã€2026 æ–°å¢ã€‘å¹»è§‰æ£€æµ‹è¾…åŠ©: è¯†åˆ«è¾“å‡ºä¸­ä¸å­˜åœ¨äºåŸæ–‡çš„å®ä½“

æ ¸å¿ƒç»„ä»¶:
- SemanticConsistencyVerifier: NLI é©±åŠ¨çš„å‡è´Ÿæ ·æœ¬è¿‡æ»¤å™¨
- CoTFaithfulnessChecker: æ¨ç†-è¾“å‡ºä¸€è‡´æ€§æ£€æµ‹å™¨ (æ–°å¢)
============================================================================
"""
import torch
import json
import re
import time
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import logging
from typing import Dict, List, Tuple, Optional

logger = logging.getLogger("OGLANS")

class SemanticConsistencyVerifier:
    """
    SCV: Semantic Consistency Verification
    åŸºäº NLI æ¨¡å‹è¿‡æ»¤ 'å‡è´Ÿæ ·æœ¬' (False Negatives)ã€‚
    å½“å‰æ¨¡å‹: Fengshenbang/Erlangshen-MegatronBert-1.3B-NLI
    è¯´æ˜ï¼šå·²ç§»é™¤ pipelineï¼Œæ”¹ç”¨åŸç”Ÿæ¨¡å‹æ¨ç†ä»¥é¿å…ä¸²è¡Œè­¦å‘Šã€‚
    """
    def __init__(
        self,
        model_name: str,
        threshold: float = 0.8,
        progress_log_interval: int = 200,
        progress_log_seconds: float = 30.0,
    ):
        self.threshold = threshold
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.progress_log_interval = max(1, int(progress_log_interval))
        self.progress_log_seconds = max(5.0, float(progress_log_seconds))
        self._calls = 0
        self._total_windows = 0
        self._total_time_seconds = 0.0
        self._last_progress_log_ts = time.perf_counter()
        
        logger.info(f"Loading SCV model: {model_name}...")
        
        # 1. å°è¯•å®šä½æ¨¡å‹è·¯å¾„
        try:
            from modelscope import snapshot_download
            logger.info("Attempting to download from ModelScope...")
            model_path = snapshot_download(model_name, cache_dir="./models")
            logger.info(f"NLI Model saved to: {model_path}")
        except Exception as e:
            logger.warning(f"ModelScope download failed, falling back to HuggingFace: {e}")
            model_path = model_name

        # 2. åŠ è½½ Tokenizer å’Œ Model (æ›¿ä»£ Pipeline)
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path).to(self.device)
            self.model.eval() # å¼€å¯è¯„ä¼°æ¨¡å¼
        except Exception as e:
            logger.error(f"Failed to load SCV model: {e}")
            raise e
        
        # 3. éªŒè¯å¹¶ç¡®å®š entailment æ ‡ç­¾ç´¢å¼•
        self.entailment_idx = self._detect_entailment_index()
        
        # 4. ã€å…³é”®ä¿®å¤ã€‘æ–­è¨€æµ‹è¯• - ç”¨ç®€å•æ ·æœ¬éªŒè¯æ ‡ç­¾æ£€æµ‹æ˜¯å¦æ­£ç¡®
        self._validate_entailment_detection()

    def _validate_entailment_detection(self):
        """
        ä½¿ç”¨ç®€å•æµ‹è¯•æ ·æœ¬éªŒè¯ entailment æ ‡ç­¾ç´¢å¼•æ˜¯å¦æ­£ç¡®
        è¿™æ˜¯å­¦æœ¯ä¸¥è°¨æ€§çš„å…³é”®ä¿éšœï¼Œé˜²æ­¢æ ‡ç­¾åè½¬å¯¼è‡´ SCV é€»è¾‘å®Œå…¨å¤±æ•ˆ
        """
        # æµ‹è¯•ç”¨ä¾‹ï¼šæ˜æ˜¾çš„è•´å«å…³ç³»
        test_premise = "å¼ ä¸‰æ˜¯ä¸€ååŒ»ç”Ÿï¼Œåœ¨åŒ—äº¬å·¥ä½œã€‚"
        test_hypothesis_entail = "å¼ ä¸‰æ˜¯åŒ»ç”Ÿã€‚"
        test_hypothesis_contradict = "å¼ ä¸‰æ˜¯ä¸€åæ•™å¸ˆã€‚"
        
        try:
            # æµ‹è¯•è•´å«å…³ç³»
            inputs_entail = self.tokenizer(
                test_premise, test_hypothesis_entail,
                return_tensors="pt", truncation=True, max_length=128
            ).to(self.device)
            
            inputs_contradict = self.tokenizer(
                test_premise, test_hypothesis_contradict,
                return_tensors="pt", truncation=True, max_length=128
            ).to(self.device)
            
            with torch.no_grad():
                logits_entail = self.model(**inputs_entail).logits[0]
                logits_contradict = self.model(**inputs_contradict).logits[0]
                
                probs_entail = torch.softmax(logits_entail, dim=-1)
                probs_contradict = torch.softmax(logits_contradict, dim=-1)
            
            entail_score_correct = probs_entail[self.entailment_idx].item()
            entail_score_wrong = probs_contradict[self.entailment_idx].item()
            
            logger.info(f"ğŸ§ª SCV æ–­è¨€æµ‹è¯•:")
            logger.info(f"   è•´å«æ ·æœ¬çš„ entailment åˆ†æ•°: {entail_score_correct:.3f}")
            logger.info(f"   çŸ›ç›¾æ ·æœ¬çš„ entailment åˆ†æ•°: {entail_score_wrong:.3f}")
            
            # éªŒè¯é€»è¾‘ï¼šè•´å«æ ·æœ¬çš„åˆ†æ•°åº”è¯¥æ˜æ˜¾é«˜äºçŸ›ç›¾æ ·æœ¬
            if entail_score_correct <= entail_score_wrong:
                logger.error(
                    f"âŒ SCV æ–­è¨€å¤±è´¥ï¼æ ‡ç­¾ç´¢å¼•å¯èƒ½é”™è¯¯ã€‚"
                    f"è•´å«æ ·æœ¬åˆ†æ•°({entail_score_correct:.3f}) <= çŸ›ç›¾æ ·æœ¬åˆ†æ•°({entail_score_wrong:.3f})"
                )
                logger.error("   å»ºè®®ï¼šæ£€æŸ¥ NLI æ¨¡å‹çš„ label2id é…ç½®ï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®š entailment_idx")
                raise ValueError(
                    f"SCV entailment æ ‡ç­¾æ£€æµ‹éªŒè¯å¤±è´¥ï¼"
                    f"å½“å‰ entailment_idx={self.entailment_idx} å¯èƒ½ä¸æ­£ç¡®ã€‚"
                )
            else:
                logger.info(f"âœ… SCV æ–­è¨€æµ‹è¯•é€šè¿‡ï¼Œentailment_idx={self.entailment_idx} éªŒè¯æ­£ç¡®")
                
        except Exception as e:
            if "æ–­è¨€å¤±è´¥" in str(e) or "éªŒè¯å¤±è´¥" in str(e):
                raise  # é‡æ–°æŠ›å‡ºéªŒè¯å¤±è´¥çš„å¼‚å¸¸
            logger.warning(f"âš ï¸ SCV æ–­è¨€æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}ï¼Œè·³è¿‡éªŒè¯")

    def _detect_entailment_index(self) -> int:
        """
        æ£€æµ‹ NLI æ¨¡å‹çš„ entailment æ ‡ç­¾ç´¢å¼•
        ä¸åŒæ¨¡å‹å¯èƒ½ä½¿ç”¨ä¸åŒçš„æ ‡ç­¾é¡ºåºï¼š
        - å¸¸è§é¡ºåº1: [entailment, neutral, contradiction] -> entailment=0
        - å¸¸è§é¡ºåº2: [contradiction, neutral, entailment] -> entailment=2
        """
        labels = getattr(self.model.config, "label2id", None)
        id2label = getattr(self.model.config, "id2label", None)
        
        # æ‰“å°æ ‡ç­¾æ˜ å°„ç”¨äºè°ƒè¯•
        logger.info(f"ğŸ“‹ NLI æ¨¡å‹æ ‡ç­¾é…ç½®:")
        logger.info(f"   label2id: {labels}")
        logger.info(f"   id2label: {id2label}")
        
        entailment_idx = 0  # é»˜è®¤å€¼
        
        if labels is not None:
            # å°è¯•å¤šç§å¯èƒ½çš„ entailment æ ‡ç­¾åç§°
            for key in ['entailment', 'ENTAILMENT', 'Entailment', 'è•´å«']:
                if key in labels:
                    entailment_idx = labels[key]
                    logger.info(f"âœ… æ£€æµ‹åˆ° entailment æ ‡ç­¾: '{key}' -> index={entailment_idx}")
                    return entailment_idx
        
        # å¦‚æœ label2id ä¸­æ²¡æœ‰æ˜ç¡®çš„ entailmentï¼Œå°è¯•ä» id2label æ¨æ–­
        if id2label is not None:
            for idx, label_name in id2label.items():
                if 'entail' in str(label_name).lower():
                    entailment_idx = int(idx)
                    logger.info(f"âœ… ä» id2label æ¨æ–­ entailment æ ‡ç­¾: '{label_name}' -> index={entailment_idx}")
                    return entailment_idx
        
        # æ— æ³•ç¡®å®šæ—¶å‘å‡ºè­¦å‘Š
        logger.warning(f"âš ï¸ æ— æ³•è‡ªåŠ¨æ£€æµ‹ entailment æ ‡ç­¾ç´¢å¼•ï¼Œä½¿ç”¨é»˜è®¤å€¼ {entailment_idx}")
        logger.warning(f"   è¯·éªŒè¯æ¨¡å‹çš„æ ‡ç­¾é¡ºåºæ˜¯å¦æ­£ç¡®ï¼")
        return entailment_idx
    
    def _json_to_natural_language(self, json_str: str) -> str:
        """
        å°† JSON æ ¼å¼çš„äº‹ä»¶ä¿¡æ¯è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€é™ˆè¿°
        è§£å†³ NLI æ¨¡å‹å¯¹ JSON æ ¼å¼è¾“å…¥çš„ OOD é—®é¢˜
        
        ç¤ºä¾‹:
        è¾“å…¥: '{"event_type": "èèµ„", "arguments": [{"role": "é‡‘é¢", "argument": "1äº¿"}]}'
        è¾“å‡º: "å‘ç”Ÿäº†èèµ„äº‹ä»¶ï¼Œé‡‘é¢ä¸º1äº¿"
        """
        try:
            # å°è¯•è§£æ JSON
            if isinstance(json_str, str):
                data = json.loads(json_str)
            else:
                data = json_str
            
            # å¤„ç†å•ä¸ªäº‹ä»¶æˆ–äº‹ä»¶åˆ—è¡¨
            if isinstance(data, list):
                events = data
            else:
                events = [data]
            
            sentences = []
            for event in events:
                event_type = event.get('event_type', 'æœªçŸ¥äº‹ä»¶')
                arguments = event.get('arguments', [])
                
                if arguments:
                    arg_parts = []
                    for arg in arguments:
                        role = arg.get('role', '')
                        value = arg.get('argument', '')
                        if role and value:
                            arg_parts.append(f"{role}ä¸º{value}")
                    
                    if arg_parts:
                        arg_str = "ï¼Œ".join(arg_parts)
                        sentences.append(f"å‘ç”Ÿäº†{event_type}äº‹ä»¶ï¼Œå…¶ä¸­{arg_str}")
                    else:
                        sentences.append(f"å‘ç”Ÿäº†{event_type}äº‹ä»¶")
                else:
                    sentences.append(f"å‘ç”Ÿäº†{event_type}äº‹ä»¶")
            
            return "ã€‚".join(sentences) + "ã€‚" if sentences else json_str
            
        except (json.JSONDecodeError, TypeError, AttributeError) as e:
            # JSON è§£æå¤±è´¥æ—¶ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²çš„ç®€åŒ–æè¿°
            logger.debug(f"JSON è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ ¼å¼: {e}")
            return f"è¿™æ®µæ–‡æœ¬åŒ…å«äº†ä»¥ä¸‹äº‹ä»¶ä¿¡æ¯ï¼š{json_str}"

    def is_false_negative(self, premise: str, hypothesis_json: str) -> bool:
        """
        åˆ¤æ–­ç”Ÿæˆçš„è´Ÿæ ·æœ¬æ˜¯å¦åœ¨è¯­ä¹‰ä¸Šå…¶å®æ˜¯æ­£ç¡®çš„ï¼ˆè•´å«å…³ç³»ï¼‰ã€‚
        
        ã€å…³é”®ä¿®å¤ã€‘å®ç°æ»‘çª—æœºåˆ¶å¤„ç†é•¿æ–‡æ¡£ï¼š
        - å¯¹äºè¶…è¿‡ NLI æ¨¡å‹ max_length çš„é•¿æ–‡æ¡£ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£
        - å–æ‰€æœ‰çª—å£ä¸­ entailment åˆ†æ•°çš„æœ€å¤§å€¼
        - è¿™ç¡®ä¿å³ä½¿äº‹ä»¶è®ºå…ƒå‡ºç°åœ¨æ–‡æ¡£ååŠéƒ¨åˆ†ä¹Ÿèƒ½è¢«æ­£ç¡®æ ¡éªŒ
        """
        call_start_ts = time.perf_counter()

        # å…œåº•ï¼šå¦‚æœè¾“å…¥ä¸ºç©ºï¼Œç›´æ¥è·³è¿‡æ ¡éªŒï¼ˆè§†ä¸ºéå‡è´Ÿä¾‹ï¼Œä¿ç•™æ ·æœ¬ï¼‰
        if not premise or not hypothesis_json:
            return False

        # ã€å…³é”®ä¿®å¤ã€‘å°† JSON è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€é™ˆè¿°ï¼Œæé«˜ NLI å‡†ç¡®æ€§
        hypothesis = self._json_to_natural_language(hypothesis_json)
        
        # è®¡ç®— hypothesis çš„ token é•¿åº¦ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
        hypothesis_len = len(hypothesis)
        max_premise_len = 512 - hypothesis_len - 20
        if max_premise_len < 100:
            max_premise_len = 100
        
        # ã€å…³é”®ä¿®å¤ã€‘æ»‘çª—æœºåˆ¶å¤„ç†é•¿æ–‡æ¡£
        if len(premise) <= max_premise_len:
            # çŸ­æ–‡æ¡£ï¼šç›´æ¥å¤„ç†
            windows = [premise]
        else:
            # é•¿æ–‡æ¡£ï¼šä½¿ç”¨æ»‘åŠ¨çª—å£
            # çª—å£å¤§å° = max_premise_len, æ­¥é•¿ = max_premise_len // 2 (50% é‡å )
            window_size = max_premise_len
            step_size = max(window_size // 2, 100)
            windows = []
            
            for start in range(0, len(premise), step_size):
                end = min(start + window_size, len(premise))
                window = premise[start:end]
                if len(window) >= 50:  # å¿½ç•¥è¿‡çŸ­çš„å°¾éƒ¨ç‰‡æ®µ
                    windows.append(window)
                if end >= len(premise):
                    break
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªçª—å£
            if not windows:
                windows = [premise[:max_premise_len]]
            
            logger.debug(f"SCV æ»‘çª—: æ–‡æ¡£é•¿åº¦ {len(premise)}, çª—å£æ•° {len(windows)}")
        
        # å¯¹æ¯ä¸ªçª—å£è®¡ç®— entailment åˆ†æ•°ï¼Œå–æœ€å¤§å€¼
        max_entailment_score = 0.0
        
        try:
            for window in windows:
                inputs = self.tokenizer(
                    window, 
                    hypothesis, 
                    return_tensors="pt", 
                    truncation=True, 
                    max_length=512
                ).to(self.device)

                with torch.no_grad():
                    outputs = self.model(**inputs)
                    probs = torch.softmax(outputs.logits, dim=-1)[0]
                
                entailment_score = probs[self.entailment_idx].item()
                max_entailment_score = max(max_entailment_score, entailment_score)
                
                # æå‰ç»ˆæ­¢ï¼šå¦‚æœå·²ç»è¶…è¿‡é˜ˆå€¼ï¼Œæ— éœ€ç»§ç»­
                if max_entailment_score > self.threshold:
                    break
            
            # é€»è¾‘ï¼šå¦‚æœè•´å«åˆ†æ•°è¿‡é«˜ï¼Œè¯´æ˜è¯¥è´Ÿæ ·æœ¬å…¶å®æ˜¯å¯¹çš„ -> åˆ¤ä¸ºå‡è´Ÿæ ·æœ¬ -> ä¸¢å¼ƒ
            if max_entailment_score > self.threshold:
                return True
            
            return False
            
        except Exception as e:
            logger.warning(f"SCV check failed: {str(e)}")
            return False
        finally:
            self._calls += 1
            self._total_windows += len(windows)
            elapsed = time.perf_counter() - call_start_ts
            self._total_time_seconds += elapsed

            now = time.perf_counter()
            should_log = (
                self._calls % self.progress_log_interval == 0
                or (now - self._last_progress_log_ts) >= self.progress_log_seconds
            )
            if should_log:
                avg_windows = self._total_windows / max(self._calls, 1)
                avg_time_ms = self._total_time_seconds * 1000.0 / max(self._calls, 1)
                throughput = self._calls / max(self._total_time_seconds, 1e-6)
                logger.info(
                    "ğŸ” SCV å¿ƒè·³: "
                    f"calls={self._calls}, avg_windows={avg_windows:.2f}, "
                    f"avg_time={avg_time_ms:.1f}ms, throughput={throughput:.2f} checks/s"
                )
                self._last_progress_log_ts = now


# =========================================================================
# ä»¥ä¸‹ç±»ç›®å‰æœªè¢«é›†æˆä½¿ç”¨ï¼Œä¿ç•™ä¾›æœªæ¥æ‰©å±•
# å½“å‰ evaluate.py ä½¿ç”¨å†…è”å®ç° (AcademicEventEvaluator.check_hallucination)
# å¦‚éœ€ä½¿ç”¨å®Œæ•´ç‰ˆæœ¬ï¼Œå¯å¯¼å…¥è¿™äº›ç±»æ›¿æ¢å†…è”å®ç°
# =========================================================================

class CoTFaithfulnessChecker:
    """
    ã€2026 æ–°å¢ã€‘ã€æš‚æœªé›†æˆã€‘CoT-JSON ä¸€è‡´æ€§æ£€æµ‹å™¨
    
    æ³¨æ„: å½“å‰æœªè¢«ä½¿ç”¨ã€‚evaluate.py ä¸­æœ‰ç®€åŒ–çš„å†…è”å®ç°ã€‚
    æ­¤ç±»æä¾›æ›´å®Œæ•´çš„æ£€æµ‹åŠŸèƒ½ï¼ŒåŒ…æ‹¬äº‹ä»¶ç±»å‹ã€è®ºå…ƒã€æ•°å€¼ä¸€è‡´æ€§æ£€æŸ¥ã€‚
    
    æ£€æµ‹ Chain-of-Thought æ¨ç†è¿‡ç¨‹ä¸æœ€ç»ˆ JSON è¾“å‡ºä¹‹é—´çš„ä¸€è‡´æ€§ã€‚
    è¿™æ˜¯ 2026 å¹´è®ºæ–‡çš„å…³é”®è¯„ä¼°æŒ‡æ ‡ä¹‹ä¸€ï¼Œç”¨äºå‘ç°"æ¨ç†ä¸æŠ½å–ä¸ä¸€è‡´"çš„å¹»è§‰é—®é¢˜ã€‚
    
    æ£€æµ‹ç»´åº¦:
    1. äº‹ä»¶ç±»å‹ä¸€è‡´æ€§: CoT æåˆ°çš„äº‹ä»¶ç±»å‹æ˜¯å¦ä¸ JSON è¾“å‡ºåŒ¹é…
    2. è®ºå…ƒä¸€è‡´æ€§: CoT ä¸­æå–çš„è®ºå…ƒæ˜¯å¦å‡ºç°åœ¨ JSON è¾“å‡ºä¸­
    3. æ•°å€¼ä¸€è‡´æ€§: æ•°å€¼æ˜¯å¦åœ¨ CoT å’Œ JSON ä¸­ä¿æŒä¸€è‡´
    """
    
    # äº‹ä»¶ç±»å‹æ­£åˆ™æ¨¡å¼
    EVENT_TYPE_PATTERN = re.compile(r'(?:äº‹ä»¶ç±»å‹|æ£€æµ‹åˆ°|è§¦å‘|å‘ç”Ÿäº†)[:ï¼š]?\s*[ã€Œ"\']*([^ã€Œã€"\'ï¼Œã€‚\n]+)[ã€"\']*')
    
    # è®ºå…ƒæå–æ¨¡å¼
    ARGUMENT_PATTERN = re.compile(r'([^\s=:ï¼š]+)\s*[=:ï¼š]\s*[ã€Œ"\']*([^ã€Œã€"\',ï¼Œã€‚\n]+)[ã€"\']*')
    
    # æ•°å€¼æ¨¡å¼
    NUMBER_PATTERN = re.compile(r'(\d+(?:\.\d+)?)\s*(?:äº¿|ä¸‡|å…ƒ|%|è‚¡|ä»½)?')
    
    def __init__(self):
        self.stats = {
            "total_checked": 0,
            "type_consistent": 0,
            "argument_consistent": 0,
            "value_consistent": 0,
            "fully_consistent": 0
        }
    
    def extract_cot_info(self, cot_text: str) -> Dict:
        """ä» CoT æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯"""
        # æå–äº‹ä»¶ç±»å‹
        event_types = set()
        for match in self.EVENT_TYPE_PATTERN.finditer(cot_text):
            event_types.add(match.group(1).strip())
        
        # æå–è®ºå…ƒ
        arguments = {}
        for match in self.ARGUMENT_PATTERN.finditer(cot_text):
            role = match.group(1).strip()
            value = match.group(2).strip()
            if len(role) <= 10 and len(value) <= 50:  # è¿‡æ»¤å™ªå£°
                arguments[role] = value
        
        # æå–æ•°å€¼
        numbers = set()
        for match in self.NUMBER_PATTERN.finditer(cot_text):
            numbers.add(match.group(1))
        
        return {
            "event_types": event_types,
            "arguments": arguments,
            "numbers": numbers
        }
    
    def extract_json_info(self, json_str: str) -> Dict:
        """ä» JSON è¾“å‡ºä¸­æå–å…³é”®ä¿¡æ¯"""
        event_types = set()
        arguments = {}
        numbers = set()
        
        try:
            # æ¸…ç† JSON å­—ç¬¦ä¸²
            json_start = json_str.find("```json")
            json_end = json_str.rfind("```")
            
            if json_start != -1 and json_end > json_start:
                content = json_str[json_start + 7:json_end].strip()
            else:
                content = json_str.strip()
            
            events = json.loads(content)
            
            if isinstance(events, list):
                for event in events:
                    if isinstance(event, dict):
                        etype = event.get("event_type", "")
                        if etype:
                            event_types.add(etype)
                        
                        for arg in event.get("arguments", []):
                            if isinstance(arg, dict):
                                role = arg.get("role", "")
                                value = str(arg.get("argument", ""))
                                if role and value:
                                    arguments[role] = value
                                    # æå–æ•°å€¼
                                    for match in self.NUMBER_PATTERN.finditer(value):
                                        numbers.add(match.group(1))
        except:
            pass
        
        return {
            "event_types": event_types,
            "arguments": arguments,
            "numbers": numbers
        }
    
    def check_faithfulness(self, full_response: str) -> Dict:
        """
        æ£€æŸ¥ CoT ä¸ JSON çš„ä¸€è‡´æ€§
        
        Args:
            full_response: åŒ…å« <thought> å’Œ JSON çš„å®Œæ•´å“åº”
        
        Returns:
            ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ
        """
        self.stats["total_checked"] += 1
        
        result = {
            "is_type_consistent": False,
            "is_argument_consistent": False,
            "is_value_consistent": False,
            "is_fully_consistent": False,
            "type_overlap_ratio": 0.0,
            "argument_overlap_ratio": 0.0,
            "value_overlap_ratio": 0.0,
            "details": {}
        }
        
        # åˆ†ç¦» CoT å’Œ JSON
        thought_match = re.search(r'<thought>(.*?)</thought>', full_response, re.DOTALL)
        if not thought_match:
            # æ²¡æœ‰ thought æ ‡ç­¾ï¼Œå°è¯•æŸ¥æ‰¾ ```json ä¹‹å‰çš„å†…å®¹
            json_start = full_response.find("```json")
            if json_start > 0:
                cot_text = full_response[:json_start]
            else:
                cot_text = ""
        else:
            cot_text = thought_match.group(1)
        
        # æå–ä¿¡æ¯
        cot_info = self.extract_cot_info(cot_text)
        json_info = self.extract_json_info(full_response)
        
        # æ£€æŸ¥äº‹ä»¶ç±»å‹ä¸€è‡´æ€§
        if cot_info["event_types"] and json_info["event_types"]:
            overlap = len(cot_info["event_types"] & json_info["event_types"])
            union = len(cot_info["event_types"] | json_info["event_types"])
            result["type_overlap_ratio"] = overlap / union if union > 0 else 0.0
            result["is_type_consistent"] = result["type_overlap_ratio"] >= 0.5
        elif not cot_info["event_types"] and not json_info["event_types"]:
            result["is_type_consistent"] = True
            result["type_overlap_ratio"] = 1.0
        
        # æ£€æŸ¥è®ºå…ƒä¸€è‡´æ€§
        if cot_info["arguments"] and json_info["arguments"]:
            cot_values = set(cot_info["arguments"].values())
            json_values = set(json_info["arguments"].values())
            overlap = len(cot_values & json_values)
            union = len(cot_values | json_values)
            result["argument_overlap_ratio"] = overlap / union if union > 0 else 0.0
            result["is_argument_consistent"] = result["argument_overlap_ratio"] >= 0.3
        elif not cot_info["arguments"] and not json_info["arguments"]:
            result["is_argument_consistent"] = True
            result["argument_overlap_ratio"] = 1.0
        
        # æ£€æŸ¥æ•°å€¼ä¸€è‡´æ€§
        if cot_info["numbers"] and json_info["numbers"]:
            overlap = len(cot_info["numbers"] & json_info["numbers"])
            union = len(cot_info["numbers"] | json_info["numbers"])
            result["value_overlap_ratio"] = overlap / union if union > 0 else 0.0
            result["is_value_consistent"] = result["value_overlap_ratio"] >= 0.5
        elif not cot_info["numbers"] and not json_info["numbers"]:
            result["is_value_consistent"] = True
            result["value_overlap_ratio"] = 1.0
        
        # ç»¼åˆåˆ¤æ–­
        result["is_fully_consistent"] = (
            result["is_type_consistent"] and 
            result["is_argument_consistent"] and 
            result["is_value_consistent"]
        )
        
        # æ›´æ–°ç»Ÿè®¡
        if result["is_type_consistent"]:
            self.stats["type_consistent"] += 1
        if result["is_argument_consistent"]:
            self.stats["argument_consistent"] += 1
        if result["is_value_consistent"]:
            self.stats["value_consistent"] += 1
        if result["is_fully_consistent"]:
            self.stats["fully_consistent"] += 1
        
        result["details"] = {
            "cot_event_types": list(cot_info["event_types"]),
            "json_event_types": list(json_info["event_types"]),
            "cot_argument_count": len(cot_info["arguments"]),
            "json_argument_count": len(json_info["arguments"])
        }
        
        return result
    
    def get_faithfulness_score(self) -> float:
        """è·å–æ•´ä½“ CoT å¿ å®åº¦åˆ†æ•°"""
        if self.stats["total_checked"] == 0:
            return 1.0
        return self.stats["fully_consistent"] / self.stats["total_checked"]
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats["total_checked"] or 1
        return {
            "total_checked": self.stats["total_checked"],
            "type_consistency_rate": self.stats["type_consistent"] / total,
            "argument_consistency_rate": self.stats["argument_consistent"] / total,
            "value_consistency_rate": self.stats["value_consistent"] / total,
            "full_consistency_rate": self.stats["fully_consistent"] / total
        }


class HallucinationDetector:
    """
    ã€2026 æ–°å¢ã€‘ã€æš‚æœªé›†æˆã€‘å¹»è§‰æ£€æµ‹å™¨
    
    æ³¨æ„: å½“å‰æœªè¢«ä½¿ç”¨ã€‚evaluate.py ä¸­æœ‰ç®€åŒ–çš„å†…è”å®ç°ã€‚
    æ­¤ç±»æä¾›æ›´å®Œæ•´çš„æ£€æµ‹åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ¨¡ç³ŠåŒ¹é…å’Œè¯¦ç»†ç»Ÿè®¡ã€‚
    
    æ£€æµ‹æ¨¡å‹è¾“å‡ºä¸­æ˜¯å¦åŒ…å«åŸæ–‡æœªæåŠçš„å®ä½“ï¼ˆå¹»è§‰ï¼‰ã€‚
    è¿™æ˜¯ 2026 å¹´è®ºæ–‡çš„å…³é”®è¯„ä¼°æŒ‡æ ‡ä¹‹ä¸€ã€‚
    """
    
    def __init__(self):
        self.stats = {
            "total_checked": 0,
            "hallucination_count": 0,
            "hallucinated_entities": []
        }
    
    def detect_hallucination(
        self, 
        source_text: str, 
        model_output: str,
        check_entities: bool = True,
        check_numbers: bool = True
    ) -> Dict:
        """
        æ£€æµ‹å¹»è§‰
        
        Args:
            source_text: åŸå§‹è¾“å…¥æ–‡æœ¬
            model_output: æ¨¡å‹è¾“å‡ºï¼ˆJSON æ ¼å¼ï¼‰
            check_entities: æ˜¯å¦æ£€æŸ¥å®ä½“å¹»è§‰
            check_numbers: æ˜¯å¦æ£€æŸ¥æ•°å€¼å¹»è§‰
        
        Returns:
            å¹»è§‰æ£€æµ‹ç»“æœ
        """
        self.stats["total_checked"] += 1
        
        result = {
            "has_hallucination": False,
            "hallucinated_items": [],
            "total_items": 0,
            "hallucination_rate": 0.0
        }
        
        # æå– JSON ä¸­çš„æ‰€æœ‰è®ºå…ƒå€¼
        try:
            json_start = model_output.find("```json")
            json_end = model_output.rfind("```")
            
            if json_start != -1 and json_end > json_start:
                content = model_output[json_start + 7:json_end].strip()
            else:
                content = model_output.strip()
            
            events = json.loads(content)
            
            all_values = []
            if isinstance(events, list):
                for event in events:
                    if isinstance(event, dict):
                        for arg in event.get("arguments", []):
                            if isinstance(arg, dict):
                                value = str(arg.get("argument", ""))
                                if value:
                                    all_values.append(value)
            
            result["total_items"] = len(all_values)
            
            # æ£€æŸ¥æ¯ä¸ªå€¼æ˜¯å¦å‡ºç°åœ¨åŸæ–‡ä¸­
            for value in all_values:
                # æ¸…ç†å€¼
                clean_value = value.strip()
                if len(clean_value) < 2:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åœ¨åŸæ–‡ä¸­
                if clean_value not in source_text:
                    # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå»æ‰ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
                    clean_source = re.sub(r'\s+', '', source_text)
                    clean_check = re.sub(r'\s+', '', clean_value)
                    
                    if clean_check not in clean_source:
                        result["hallucinated_items"].append(value)
                        result["has_hallucination"] = True
            
            if result["total_items"] > 0:
                result["hallucination_rate"] = len(result["hallucinated_items"]) / result["total_items"]
            
            if result["has_hallucination"]:
                self.stats["hallucination_count"] += 1
                self.stats["hallucinated_entities"].extend(result["hallucinated_items"][:3])  # åªä¿ç•™å‰3ä¸ª
            
        except Exception as e:
            logger.debug(f"Hallucination detection error: {e}")
        
        return result
    
    def get_hallucination_rate(self) -> float:
        """è·å–æ•´ä½“å¹»è§‰ç‡"""
        if self.stats["total_checked"] == 0:
            return 0.0
        return self.stats["hallucination_count"] / self.stats["total_checked"]
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_checked": self.stats["total_checked"],
            "hallucination_count": self.stats["hallucination_count"],
            "hallucination_rate": self.get_hallucination_rate(),
            "sample_hallucinated_entities": self.stats["hallucinated_entities"][-10:]
        }
